# Standardized benchmarking script.
# Generated by ChatGPT mostly
# Call with the name of the tests executable, wherever it is located. (Typically in the CMake build directory)
# TODO fix this

import re
import pandas as pd
import sys
import time
import subprocess

def run_benchmarks():
    # Run the binary in sys.argv[1] with argument "[bench]" and return the output as a string.
    print("Running benchmarks (this may take a while)...")
    process = subprocess.Popen([sys.argv[1], "[bench]"], stdout=subprocess.PIPE)
    lines = []
    while process.poll() is None:
        line = process.stdout.readline()
        if line:
            lines.append(line.decode("utf-8"))
        else:
            time.sleep(0.01)
    output = "\n".join(lines)
    if process.returncode != 0:
        raise Exception("Benchmarking failed")
    return output

benchmark_output = run_benchmarks()

# Function to extract benchmark names and times
def extract_benchmark_times(output):
    benchmark_map = {}

    # Regular expression to match benchmark name and time
    benchmark_pattern = re.compile(
        r"^(?P<name>.+?)\s+\d+\s+\d+\s+(?P<time>\d+\.\d+)\s*(?P<unit>s|ms)$",
        re.MULTILINE
    )

    for match in benchmark_pattern.finditer(output):
        name = match.group("name").strip()
        time = float(match.group("time"))
        unit = match.group("unit")

        # Convert time to seconds if it's in milliseconds
        if unit == "ms":
            time /= 1000

        benchmark_map[name] = time

    return benchmark_map

# Extract the benchmark map
benchmark_map = extract_benchmark_times(benchmark_output)

# Function to update benchmark results in a CSV
def update_benchmark_csv(csv_path, benchmark_map, commit_hash, timestamp):
    try:
        # Read the existing CSV
        df = pd.read_csv(csv_path)
    except FileNotFoundError:
        # If the file doesn't exist, create a new DataFrame
        df = pd.DataFrame()

    # Add the commit hash and timestamp columns if not present
    if "commit_hash" not in df.columns:
        df["commit_hash"] = None
    if "timestamp" not in df.columns:
        df["timestamp"] = None

    # Add new benchmark columns if necessary
    for benchmark in benchmark_map:
        if benchmark not in df.columns:
            df[benchmark] = None

    # Append the new results
    new_row = {"commit_hash": commit_hash, "timestamp": timestamp, **benchmark_map}
    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)

    # Write the updated DataFrame back to the CSV
    df.to_csv(csv_path, index=False)

csv_path = "bench_results.csv"

# Get current commit hash and its timestamp using git commands
commit_hash = subprocess.check_output(["git", "rev-parse", "HEAD"]).strip().decode("utf-8")
# Timestamp of the commit
timestamp = int(subprocess.check_output(["git", "show", "-s", "--format=%ct", "HEAD"]).strip())

update_benchmark_csv(csv_path, benchmark_map, commit_hash, timestamp)
